{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's get into practical applications! In this part, we'll work with numbers and images, do some basic analysis, and learn how to display our findings.\n",
    "\n",
    "# Libraries\n",
    "These are all open-source libraries we had to install with pip after downloading Python. They do not come with the default Python installation, but they are very useful add-ons for the scientist. As you go through your research, keep in mind that there are many other useful libraries that have been created for Python. If you search around online, you may discover these, install them with pip, and use them to do your research more efficiently.\n",
    "\n",
    "## Implementing libraries\n",
    "To start using a library we've installed, we must `import` it in our Python file. Good coding practice should have these import statements at the top of your file. This helps one keep track of the external libraries we've imported. There are a few ways we can import. Here are some examples, which we'll explain below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. `import scipy` - simple import**\n",
    "- This is the simplest method. We just write `import` followed by the name of the library we want (in this example, scipy).\n",
    "- To call functions, the syntax is `library_name.function_name()`, e.g. \"scipy.1d()\"\n",
    "\n",
    "**2. `import numpy as np` - import with alias**\n",
    "- This is exactly the same as above, except we give our library a nickname (I call it an alias) because typing extra letters all the time is exhausting. In this case, the alias is \"np\". There are a few standard ones you will see in other code, and \"np\" for \"numpy\" is a common one.\n",
    "- To call functions, the syntax is `alias_name.function_name()`, e.g. \"numpy.array()\"\n",
    "\n",
    "**3. `import matplotlib.pyplot as plt` - import sub-module**\n",
    "- This is just like the above methods, except we have an extra dot and name after the main library name.\n",
    "- This can include or not include an alias.\n",
    "\n",
    "**4. `from scipy.optimize import curve_fit` - direct import functions**\n",
    "- In this case, we bypass the need to include library names and directly import a function, in this case `curve_fit`.\n",
    "- If  you import with `from library_name import a_function`, the only thing you have imported is `function`. You call it like any other function, with no need for the library name.\n",
    "- This can include or not include sub-modules like above. In this case we use \"optimize\" from \"scipy\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll start working with these libraries. A lot of their names have hints as to their utility. (\"Num\" for numbers, \"sci\" for science, \"plot\" for... well, plots). Most of these libraries have docstrings as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>EX 3.1 - Get extra library info</mark>\n",
    "\n",
    "*Print the docstring of one of the libraries imported above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy\n",
    "NumPy is a powerful numerical computing package for Python. It comes with its own data classes, most notably the **numpy array**  (or just \"array\" for short), which is similar to a list or list of lists up to \"n\" dimensions (n-d), except it has some stricter requirements and even more useful functions and attributes. A Python **class** is a custom data type you can define to bundle data and functionality together for your unique application. We won't get in the specifics of classes here, but you can read more [here](https://docs.python.org/3/tutorial/classes.html). For our purposes, we will just use other library classes.\n",
    "\n",
    "## NumPy arrays\n",
    "NumPy is especially handy for working with multi-dimensional arrays. This is different from the Python list-of-lists in a few key ways:\n",
    "- array elements must all have the **dtype**, or data type\n",
    "- array sublists must all be the same length (think n-dimensional rectangular prism)\n",
    "- array **size** is fixed after creation (you cannot append/pop)\n",
    "- array **shape** can be changed, as long as the size is the same\n",
    "- arrays can act like vectors and matrices for math operations\n",
    "\n",
    "`dtype`, `size`, and `shape` are **attributes** of every NumPy array. `dtype` is the data type of each element, `size` gives you the total number of elements in an array, and `shape` gives you the number of elements along each axis. You can reference them with syntax like a function from a library, but without the parentheses:\n",
    "```\n",
    "arr_element_type = my_array.dtype\n",
    "arr_shape = my_array.shape\n",
    "arr_size = my_array.size\n",
    "```\n",
    "\n",
    "Let's get working with numpy arrays. There are a number of ways to create, or **initialize** an array:\n",
    "- convert a list to an array with `np.array(my_list)`\n",
    "- read a data file with `np.fromfile(filename)`\n",
    "- call a numpy function like `np.empty(), np.zeros(), np.ones()`\n",
    "\n",
    "For the functions `np.empty(), np.zeros(), np.ones()`, you typically pass one or two arguments:\n",
    "```\n",
    "my_array = np.ones(shape, dtype=data_type)\n",
    "```\n",
    "- `shape` can be either an integer (to create a vector) or a list of $n$ integers (to create an $n$-d matrix)\n",
    "- `data_type` is something like \"float\", \"int\", or other data types we learned about, with which the array is populated. It is optional and will d\n",
    "\n",
    "There are also some numpy-specific data types if you want to look into those: [link](https://numpy.org/doc/stable/reference/arrays.scalars.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>EX 3.2 - Our first numpy array</mark>\n",
    "*Based on what we've learned so far, let's try to predict the outputs of the following print statements.*\n",
    "\n",
    "1. Before running the cell below, look at the variable \"matrix\".\n",
    "2. What do you think will be the result of each print statement? Write your answers in comments on each line.\n",
    "3. Run the cell and check your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([[1,2,3,4], [5,6,6,8], [8,9,10,11]], dtype=float)\n",
    "\n",
    "print(matrix)\n",
    "print(type(matrix))\n",
    "print(matrix.dtype)\n",
    "print(matrix.size)\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes: `type(matrix)` is NOT the same as `matrix.dtype`, and `matrix.size` is equal to the product of the values in `matrix.shape`. Is this what you expected? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with NumPy arrays\n",
    "\n",
    "**1. Multi-dimensional indexing**\n",
    "\n",
    "Like lists, we can index arrays using brackets and index numbers, starting from 0. \n",
    "For multiple dimensions, there are a few ways we can get sub-elements. For a 2D array `M`, each single-index element `M[i]` will be a 1D array. To get a single number, we need two indices, like `M[i,j]`. As we increase the number of dimensions, this works the same way, recursively.\n",
    "\n",
    "The comma-separated indexing is unique to numpy arrays. Alternatively, you can index both arrays and lists-of-lists using extra brackets, so `M[i][j][k]` is equivalent to `M[i,j,k]`. This is because `M[i]` gives you a list, which you can then index again using brackets. I personally find this method somewhat clunkier and harder to parse.\n",
    "\n",
    "Once you have your initialized array, you can change individual elements (single elements or sub-arrays) using indices, e.g.\n",
    "```\n",
    "matrix = np.ones([2,2])\n",
    "matrix[0,0] = 100.0      # change an element\n",
    "matrix[1] = [5.0, 5.0]   # change a sub-array (size must match!)\n",
    "```\n",
    "\n",
    "**2. Reshaping**\n",
    "\n",
    "Once we have an array, we cannot change its size, but we can change its shape. For the scientist, this is most useful for reading in data. We usually read data into a 1D array, so we can easily use reshape to convert this into a 2D array (this could be a data table or an image). \n",
    "\n",
    "Remember that array size is equal to the product of the values in its shape. We can change the array shape to any other shape that fulfills this requirement using `reshape`:\n",
    "```\n",
    "reshaped_array = array.reshape(new_shape)\n",
    "```\n",
    "For example, we could reshape a 3x4 array into a 2x6 array (also 2D) or into a 1x12 (1D, fewer dimensions) or a 2x3x4 (3D, more dimensions). You can also swap dimension order, and reshape a 3x4 into a 4x3.\n",
    "\n",
    "You can also remove any multi-dimensionality or `flatten` an array into 1D. This is convenient, because you don't have to pass a \"new_shape\" argument.\n",
    "```\n",
    "flat_array = array.flatten()\n",
    "```\n",
    "\n",
    "**3. Type changing**\n",
    "\n",
    "All the elements of a numpy array must be the same, but you can reassign them using:\n",
    "```\n",
    "new_type_array = my_array.astype(new_type)\n",
    "```\n",
    "This might be handy if you want to change integers to floats for some math, or if you read in a text file and want to convert your strings to numbers.\n",
    "\n",
    "\n",
    "**4. Arithmetic**\n",
    "\n",
    "We can use the same math operators we learned in Part I with numpy arrays, either with one numpy array (any shape) and a constant, or with two numpy arrays (must be same size). The latter approach gives an element-wise result. Take a look at the outputs below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two matrices, same shape\n",
    "A = np.array([[1,1,1], [2,2,2]], dtype=float)\n",
    "B = np.array([[1,2,3], [1,2,3]], dtype=float)\n",
    "\n",
    "print('addition\\n',         A+B)\n",
    "print('subtraction\\n',      A-B)\n",
    "print('division\\n',         A/B)\n",
    "print('integer division\\n', A//B)\n",
    "print('multiplication\\n',   A*B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a constant and a matrix, any shape\n",
    "c = 2.5\n",
    "\n",
    "print('constant addition\\n',         A+c)\n",
    "print('constant subtraction\\n',      A-c)\n",
    "print('constant division\\n',         A/c)\n",
    "print('constant integer division\\n', A//c)\n",
    "print('constant multiplication\\n',   A*c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Matrix operations**\n",
    "\n",
    "NumPy also has many built-in linear algebra functions for working with matrices and vectors (1D matrices). Here are just a few you may find useful:\n",
    "- `dot_prod = np.dot(vec1, vec2)` - get dot product of two vectors\n",
    "- `A_t = np.transpose(A)` - get transpose of matrix $A$\n",
    "- `A_inv = np.linalg.inv(A)` - get inverse of matrix $A$\n",
    "- `x = np.linalg.solve(A,b)` - solve $Ax = b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <mark>EX 3.3 - array dimensions</mark>\n",
    "*If we have a 4D matrix `M_4D`, how many dimensions does `M_4D[i,j]` have? How would you index a single element?*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>EX 3.4 - difference between arrays and lists</mark>\n",
    "*I mentioned earlier that there are some key differences in lists and arrays. A big one is that you can't really do math on plain old lists. However, the multiplication operation gives an output for both lists and arrays. is there a difference?*\n",
    "\n",
    "1. Create a Python list and multiply it by a constant.\n",
    "2. Convert this list to a NumPy array and multiply it by the same constant.\n",
    "3. Is there a difference? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>EX 3.4 - modify an array</mark>\n",
    "*Create a 2D numpy array of any shape with all twos. Change the first element to your favorite number. Divide the last row by pi.*\n",
    "\n",
    "*Note: numpy comes with a saved value for pi, `np.pi`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other NumPy math\n",
    "\n",
    "**1. Useful matrix metrics**\n",
    "```\n",
    "np.mean(x)     # get the mean\n",
    "np.std(x)      # get standard deviation\n",
    "np.var(x)      # get variance\n",
    "np.max(x)      # get maximum\n",
    "np.min(x)      # get minimum\n",
    "```\n",
    "\n",
    "These functions have an optional second argument, `axis`. You pass in an index corresponding to the dimension of the axis over which you want to do the operation. For example, `np.max(M, axis=0)` will return an array with size `M.shape[0]` with the maximum of each sub-array along the 0th (first) axis.\n",
    "\n",
    "There are also some functions that operate on a single constant or element-wise over a matrix.\n",
    "\n",
    "**2. Useful math**\n",
    "```\n",
    "np.sqrt(x)     # get square root\n",
    "np.exp(x)      # get e^x\n",
    "np.log(x)      # get the NATURAL logarithm (ln)\n",
    "np.log10(x)    # get the logarithm base 10\n",
    "```\n",
    "\n",
    "**3. Trigonometry (sin, cos, and tan)**\n",
    "```\n",
    "np.sin(x)      # get sine\n",
    "np.arcsin(x)   # get inverse sine\n",
    "np.rad2deg(x)  # convert degrees -> radians\n",
    "np.deg2rad(x)  # convert radians -> degrees\n",
    "```\n",
    "\n",
    "**4. Etc.**\n",
    "```\n",
    "np.round(x)    # round to nearest integer\n",
    "np.floor(x)    # round down\n",
    "np.ceil(x)     # round up\n",
    "```\n",
    "\n",
    "Here is a full list, in case you need other operations: [link](https://numpy.org/doc/stable/reference/routines.math.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy iterables\n",
    "\n",
    "You can use NumPy to generate lists of numbers, like with `range`:\n",
    "- `np.arange(start, stop, step)` - return evenly spaced values within the given interval (like `range`)\n",
    "- `np.linspace(start, stop, num)` - return \"num\" evenly spaced values over the given interval\n",
    "\n",
    "These both return numpy arrays. I find these things are handy for creating plots. So, let's do that! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib Pyplot\n",
    "\n",
    "Data presentation skills are essential for the scientist. Matplotlib is a great library for creating figures in Python. The \"mat\" in the name comes from the fact that many plotting conventions are meant to mirror those you would use in MATLAB, so this info may also be useful if you go on to switch to that language instead of Python. I assume \"plotlib\" is for \"plot library\".\n",
    "\n",
    "Here, we'll focus on learning basic anatomy of a plot and creating code snippets you can reference later on for generating your own plots. \n",
    "\n",
    "The matplotlib website includes a number of cheatsheets, which are very useful quick reference guides: [link](https://matplotlib.org/cheatsheets/).\n",
    "\n",
    "Before we can plot, we need some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>EX 3.5 - create polynomial data</mark>\n",
    "\n",
    "1. Use a numpy function to generate an array `x` of $N=20$ equally spaced values from -5 to +5.\n",
    "2. Write a function to compute $y = ax^2 + bx + c$. \n",
    "3. Use your function to compute the array `y1` as a function of `x` for $a, b, c$ of your choice.\n",
    "4. Repeat step 3 to create `y2` with new  $a, b, c$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The simplest figure\n",
    "First, most handy plotting functions are in `matplotlib.pyplot`, which is conventionally imported as `plt`. I highly recommend you follow this convention.\n",
    "\n",
    "I find the syntax fairly intuitive. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "plt.plot(x, y1)\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the simplest plot. You plot the data, and then you show it. But we probably want to do many other things with our plots--add labels, multiple lines and legends, customize colors, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "plt.plot(x, y1)\n",
    "plt.plot(x, y2)\n",
    "\n",
    "# add some labels to the figure\n",
    "plt.title('My title')\n",
    "plt.xlabel('x values')\n",
    "plt.ylabel('y values')\n",
    "\n",
    "# customize the x ticks\n",
    "# can customize y by changing 'x' to 'y'\n",
    "plt.xticks(np.arange(-5, 5, 1))\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going even further, these functions all have optional arguments you can call to customize your plots. Most notably, if we add labels to our data, we can create a legend (which has an optional argument for a title and location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "plt.plot(x, y1, color='blue', marker='o', linestyle='-',  label='y1')\n",
    "plt.plot(x, y2, color='red',  marker='s', linestyle='--', label='y2')\n",
    "plt.legend(title='legend', loc='upper left')\n",
    "\n",
    "# add some labels to the figure\n",
    "plt.title('My title', fontsize=18, fontweight='bold')\n",
    "plt.xlabel('x values', fontsize=14)\n",
    "plt.ylabel('y values', fontsize=14)\n",
    "\n",
    "# customize the x ticks\n",
    "# can customize y by changing 'x' to 'y'\n",
    "plt.xticks(np.arange(-5, 5, 1), fontsize=12)\n",
    "plt.xlim(-8,8)\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving figures to files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save your figure, you add a line `plt.savefig(\"filename.file_extension\")` BEFORE the `plt.show()`. After we show the plot, it is flushed out of matplotlib's memory, so if we try to save a figure, we will get a blank picture. Run the code below and then check the \"output\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y1, color='blue', marker='o', linestyle='-',  label='y1')\n",
    "plt.plot(x, y2, color='red',  marker='s', linestyle='--', label='y2')\n",
    "plt.legend(title='legend', loc='upper left')\n",
    "\n",
    "plt.title('My title', fontsize=18, fontweight='bold')\n",
    "plt.xlabel('x values', fontsize=14)\n",
    "plt.ylabel('y values', fontsize=14)\n",
    "\n",
    "plt.xticks(np.arange(-5, 5, 1), fontsize=12)\n",
    "plt.xlim(-8,8)\n",
    "\n",
    "plt.savefig(\"output/first_plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subplots\n",
    "\n",
    "Our simple plot has matplotlib handling some more complex things on its back end. We can use a different method, `plt.subplots()` to manually set some of these. Most notably, we can create a figure with multiple panels. This can be a single panel, single row, single column, or multiple rows and columns. In our example, we will consider a row of 2 panels.\n",
    "\n",
    "First, the subplots function returns two values.\n",
    "```\n",
    "fig, ax = plt.subplots(num_y_panels, num_x_panels)\n",
    "```\n",
    "1. a figure object (usually `fig`) encompassing the whole figure\n",
    "2. an axes object (usually `ax`), an array of the different individual panels or \"subplots\"\n",
    "\n",
    "We can use some optional arguments here too. The ones I most typically use are `dpi=some_integer` and `figsize=[x_size, y_size]`. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, dpi=300, figsize=[4,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot on each subplot, we index `ax` to get individual panels and then call functions, like `ax[i].plot()`. \n",
    "\n",
    "For customizing each subplot like we did in the simple plot, we call analogous functions with *almost* the same name, except usually with the addition of \"set_\" before the simple function name. This is to distinguish these functions from those that change the whole figure. HOWEVER, the `plot()` and `legend()` functions are unchanged. \n",
    "\n",
    "We also have some new functions for the who figure. Most typical, you can set a \"suptitle\" over all the subplots, create a legend for the whole figure, and implement \"tight_layout\" so all elements fit nicely. I recommend calling \"tight_layout\" after everything else, but before showing the plot or saving it, to make sure everything you want to show is tightened.\n",
    "\n",
    "See the below example. <mark>*What happens if you comment out the line for tight_layout? What values for 'pad' work?*</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, dpi=100, figsize=[8,4])\n",
    "\n",
    "# first panel, i=0\n",
    "ax[0].plot(x, y1, color='b', label='y1')\n",
    "ax[0].set_title('y1')\n",
    "ax[0].set_xticks(np.arange(-5, 5, 1), fontsize=12)\n",
    "ax[0].set_xlabel('x vals')\n",
    "ax[0].legend(title='subplot 1 legend')\n",
    "\n",
    "# second panel, i=1\n",
    "ax[1].plot(x, y2, color='r', label='y2')\n",
    "ax[1].set_title('y2')\n",
    "ax[1].set_xticks(np.arange(-5, 5, 1), fontsize=12)\n",
    "ax[1].set_xlabel('x vals')\n",
    "ax[1].legend(title='subplot 2 legend')\n",
    "\n",
    "# figure functions\n",
    "fig.suptitle('The figure suptitle')\n",
    "fig.legend(title='figure legend', loc='center right')\n",
    "fig.tight_layout(pad=0.2)  # change or remove 'pad' to adjust how tight things are\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>*Notice that the y axes of both plots are different. This might present data in a hard-to-compare way. Try adding optional boolean arguments `sharex=True` and/or `sharey=True` to the first line of the block above, when we create our subplots objects. Take note of what happens.*</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you create different numbers/shapes of subplots, the functions above all stay the same, but the indexing of `ax` may change.\n",
    "\n",
    "**Single panel**\n",
    "\n",
    "I like to use the subplots function even when using a single panel, since I am more used to its functions and feel I get greater customization over the labels, figure size, etc. Beforehand, `ax` was an array that we had to index. But, if we have a single element, `ax` is not an array--it is a single subplot, so we don't index it at all. \n",
    "```\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(x,y)\n",
    "```\n",
    "\n",
    "**Single column**\n",
    "\n",
    "The functions we described above for the single row work exactly the same for a single column of subplots.\n",
    "```\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].plot(x,y)\n",
    "```\n",
    "\n",
    "**Multiple columns and rows**\n",
    "\n",
    "If we create a 2D array of subplots, you must use two indices to get a single subplot.\n",
    "```\n",
    "fig, ax = plt.subplots(2,2)\n",
    "ax[0,0].plot(x,y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style customization\n",
    "\n",
    "Matplotlib.pyplot includes an \"rcParams\" attribute that sets the style for all of your figures. All code after calling the function `plt.rcParams.update()` will use this style by default.\n",
    "This is much easier than manually setting your plot style for each individual figure you create. It is also good for quickly changing the format for all plots, which is particularly handy when you have to adjust formatting to match a conference or journal's style.\n",
    "\n",
    "Here is an example of what my typical rcParams update statement looks like. You can change the values in it to match your own preferences. You can also remove/uncomment lines to go with the matplotlib defaults, or you can add lines to customize more attributes. Each line is an attribute name in quotes, followed by a colon, then the new value, and a comma to give a new line. You can get a list of available rcParam attributes to edit by printing `plt.rcParams`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my typical style\n",
    "\n",
    "plt.rcParams.update({\n",
    "    # figure\n",
    "    \"figure.dpi\": 300,   # higher quality image\n",
    "    # text\n",
    "    \"font.size\":10,\n",
    "    #\"font.family\": \"serif\",                  # uncomment for tex style\n",
    "    #\"font.serif\": ['Computer Modern Roman'], # uncomment for tex style\n",
    "    #\"text.usetex\": True,                     # uncomment for tex style\n",
    "    # axes\n",
    "    \"axes.titlesize\": 10,\n",
    "    \"axes.labelsize\": 8,\n",
    "    \"axes.linewidth\": 1,\n",
    "    # ticks\n",
    "    \"xtick.top\": True,\n",
    "    \"ytick.right\": True,\n",
    "    \"xtick.direction\": \"in\",\n",
    "    \"ytick.direction\": \"in\",\n",
    "    \"xtick.labelsize\":8,\n",
    "    \"ytick.labelsize\":8,\n",
    "    # grid\n",
    "    \"axes.grid\" : True,\n",
    "    \"axes.grid.which\" : \"major\",\n",
    "     \"grid.color\": \"lightgray\",\n",
    "     \"grid.linestyle\": \":\",\n",
    "     # legend\n",
    "     \"legend.fontsize\":8,\n",
    "    \"legend.facecolor\":'white',\n",
    "    \"legend.framealpha\":1.0 ,  \n",
    "     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other params\n",
    "\n",
    "print(plt.rcParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are less interested in customizing your figure style and more interested in rapidly creating pretty data visualizations, I recommend you check out [seaborn](https://seaborn.pydata.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPy\n",
    "\n",
    "SciPy is the Python science package, and it has many handy functions for scientific analysis. \n",
    "For the scientist: interpolation, statistics, algebraic equations. For the mathematician: optimization, integration, eigenvalue problems, differential equations. This just a short list. The [SciPy website](https://scipy.org/) has great documentation.\n",
    "\n",
    "I am not particularly familiar with the stats packages, but I expect many scientists will be interested in the clustering packages (K-means, hierarchical, etc.) \n",
    "\n",
    "## Curve fitting\n",
    "\n",
    "One of the most broadly applicable scientific uses of SciPy (on which I can speak intelligently) is **curve fitting**. Often, we scientists gather some data, which has noise and outliers and other complications that make analysis difficult. To model our data, we can fit curves to get easier-to-digest information.\n",
    "\n",
    "At the top of this file, we imported the function `curve_fit` from `scipy.optimize`. Here is the syntax:\n",
    "```\n",
    "popt, pcov = curve_fit(function, xdata, ydata)\n",
    "```\n",
    "**Inputs**. We have three required arguments:\n",
    "- `function`, the pre-defined function for curve fitting. The first argument to this should be x (your independent variable), and subsequent arguments are the ones you want to optimize.\n",
    "- `xdata`, array of independent variable values.\n",
    "- `ydata`, array of dependent variable measured values as a function of `xdata`. Must be the same size as `xdata`.\n",
    "\n",
    "There are a number of optional arguments detailed [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html). For example, if you are getting weird output curve fits, you may want to pass `p0`, an initial guess on the parameters. Or if you know the uncertainty of your measured ydata, you should pass `sigma` to get appropriate outputs.\n",
    "\n",
    "**Outputs**. The function returns two values:\n",
    "- `popt`, a list of the optimal parameters for passing into `function` to fit your data.\n",
    "- `pcov`, the matrix estimated parameter covariance. Off-diagonal elements give covariance between parameters, and diagonal elements give the variance.\n",
    "\n",
    "If we add some noise to our earlier polynomial data, we can test this out. Let's use the `numpy.random` module to add some Gaussian noise. Take a look at the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some noise\n",
    "mean = 0.0\n",
    "stdev = 2.0  # standard deviation of noise\n",
    "N = x.size   # match the size of our data\n",
    "\n",
    "noise = np.random.normal(mean, stdev, N)\n",
    "y_noisy = y1 + noise\n",
    "\n",
    "plt.plot(x, y1, color='r', label='original y1')\n",
    "plt.plot(x, y_noisy, marker='o', ls='', label='noisy y1')  # remove the line with linestyle or ls='' (empty string)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>*How close are the optimal argument values to your original inputs? Are they within +- one standard deviation? How does the resulting best-fit curve compare to your original curve?*</mark>\n",
    "\n",
    "Now it is your turn to do some curve fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>EX 3.6 - reading data, curve fitting, and plotting</mark>\n",
    "\n",
    "*In this exercise, you will learn to read '.npy' data files and practice curve fitting/plotting.*\n",
    "\n",
    "*The file 'data/lymphocytes.npy' contains lymphocyte count measurements at different time points from a patient who was exposed to an unknown whole-body dose of radiation during an accident in their cancer treatment. We need to figure out what this dose was in order to best treat the patient for radiation syndrome. We will curve fit the lymphocyte data to estimate this dose.*\n",
    "\n",
    "*Lymphocyte depletion kinetics follow an exponential decline:*\n",
    "$$\n",
    "L(t) = L(0)e^{-Kt}\n",
    "$$\n",
    "*where K is an unknown dose-dependent rate constant that we must find through curve fitting. Dose is equal to $\\alpha K$, where $\\alpha=10.2$ Gy/day.*\n",
    "\n",
    "1. Run the block of code to read in the numpy data file. Take a look at the syntax.\n",
    "2. Curve fit the data using lyphocyte depletion kinetics.\n",
    "3. From your curve fit results, estimate dose in units of Gy.\n",
    "4. Create a plot with the best-fit lymphocyte count vs. time curve and the given data. Save it to the \"output\" folder. Note that you can create a smoother best-fit curve by creating a new \"time\" array with more data points in the given range using `np.linspace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.fromfile('data/lymphocytes.npy', dtype=float)\n",
    "\n",
    "# the first half of values are the time in days\n",
    "# the second half of values are the lymphocyte counts\n",
    "N_measurements = data.size//2\n",
    "time = data[:N_measurements]    # first half\n",
    "counts = data[N_measurements:]  # second half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images\n",
    "\n",
    "Sometimes our data is 1-dimensional, measurements of a single variable as a function of some other variable, like our lymphocyte counts above. But often times, we have complex, multi-dimensional data like  classifications of \"cancer\" or \"no cancer\" as a function of many variables.\n",
    "\n",
    "A simple introduction into handling more than 1 dimension of data is **images**. Images are just 2D arrays. A stack of images, like a multi-row CT scan, is a 3D array. If you deal with medical images, you might need to read DICOM files, for which I recommend checking out the [pydicom library](https://pydicom.github.io/). For our purposes, we will start with images read from numpy files.\n",
    "\n",
    "There are many things you might want to do with an image. Maybe you are looking at bacteria under a microscope and want to automate the process of counting individual cells. Maybe you are looking at a cancer patient and want to locate and classify a tumor. Maybe you want to measure the image quality achievable with some camera. There are many complex things you could do for these tasks, and I expect if you get really into this sort of research, you will eventually dip your toes into machine learning. \n",
    "\n",
    "Let's begin with a relatively simple task: computing the mean and standard deviation within a region-of-interest (ROI).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO! example code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>EX 3.7 - image analysis</mark>\n",
    "*A patient visits the dermatologist with a concern about a new mole she noticed. You know that mole color should be fairly uniform, and variations are concerning. Read in the image file and use an ROI measurement to assess whether this patient should have a biopsy.*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO! upload image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using functions from other files\n",
    "\n",
    "We've learned how to import other libraries. You can also use import statements with your own .py files. When coding projects get big, we might create multiple files in order to organize our functions, so this technique can be handy. Or, we can use this technique to import functions from old Python files instead of copy-pasting functions all the time.\n",
    "\n",
    "These imports can use any of the formats we covered above (import the whole file, import with alias, import functions). The file should be in your current working directory (usually the folder with the same code file you are running). We import our file using its base name without the \".py\" extension. So, importing some functions from `my_file.py` looks like:\n",
    "```\n",
    "from my_file import my_function1, my_function2\n",
    "```\n",
    "\n",
    "If your directory structure includes sub-folders and you want to reference a Python file in one of those subfolders, we can separate folder names with dots (not slashes!):\n",
    "```\n",
    "from subfolder.subsubfolder.my_file import my_func1, my_func2\n",
    "```\n",
    "\n",
    "See the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can specify the functions we want to import from our own files. \n",
    "# The file must be in the same folder where you are running this file.\n",
    "\n",
    "from my_functions import hello, goodbye  \n",
    "\n",
    "x = 'my friend'\n",
    "hello(x)\n",
    "goodbye(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall good coding style includes all import statements at the top of a file. Since we are doing this at the bottom of our file, this is bad coding practice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
